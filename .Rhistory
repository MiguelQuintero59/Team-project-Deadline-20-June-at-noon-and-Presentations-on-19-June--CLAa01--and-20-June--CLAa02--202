results <- data.frame(Iteration = integer(),
NumGenes = integer(),
FeatureSelection = logical(),
Precision = double(),
Sensitivity = double(),
Specificity = double(),
Genes = character(),
stringsAsFactors = FALSE)
set.seed(125)
# Load Data
df <- load_gene_subset(group_number = 7, include_class = TRUE)
# Extract Predictors
gene_data <- df[, setdiff(names(df), "Class")]
genes_only <- df[, setdiff(names(df), "Class")]
View(gene_data)
library(MASS)
library(fmsb)
library(pROC)
library(dplyr)
library(caret)
library(glmnet)
library(ggplot2)
library(reshape2)
library(pheatmap)
library(randomForest)
load_gene_subset <- function(group_number,
expression_file = "gene-expression-invasive-vs-noninvasive-cancer.csv",
subset_file = "teamsubsets.csv",
include_class = TRUE) {
# Load main dataset
dataframe <- read.csv(file = expression_file)
# Load subset file
df_subsets <- read.csv(file = subset_file, sep = ' ')
# Filter by group number
reg_id <- df_subsets[group_number, ]
# Extract gene indices (remove the ID column)
subsets <- as.numeric(reg_id[-1])
# Filter gene expression dataframe using selected gene indices
df <- dataframe[, subsets]
# Optionally, add class and cancer type
if (include_class) {
df$Class <- dataframe$Class
}
return(df)
}
# Initialize empty results data frame
results_table <- data.frame(
Model = character(),
Hyperparameter = character(),
Precision = numeric(),
Sensitivity = numeric(),
Specificity = numeric(),
stringsAsFactors = FALSE
)
# Define the function
add_results <- function(model, hyperparameter, featureselection, precision, sensitivity, specificity) {
new_row <- data.frame(
Model = model,
Hyperparameter = hyperparameter,
FeatureSelection = featureselection,
Precision = precision,
Sensitivity = sensitivity,
Specificity = specificity,
stringsAsFactors = FALSE
)
# Use global assignment to update results_table
assign("results_table", rbind(results_table, new_row), envir = .GlobalEnv)
}
#Read training and testing dataset
read_gene_data <- function(train_path = "data/train_data.csv", test_path = "data/test_data.csv") {
# Read the CSV files
train_df <- read.csv(train_path)
test_df <- read.csv(test_path)
# Split into genes and labels
train_genes <- train_df[, !(names(train_df) %in% "Class")]
train_labels <- train_df$Class
test_genes <- test_df[, !(names(test_df) %in% "Class")]
test_labels <- test_df$Class
# Return as a list
return(list(
train_genes = train_genes,
train_labels = train_labels,
test_genes = test_genes,
test_labels = test_labels
))
}
remove_correlated_features <- function(train_data, threshold = 0.8) {
# Compute correlation matrix
cor_matrix <- cor(train_data, method = "pearson", use = "pairwise.complete.obs")
cor_df <- as.data.frame(as.table(cor_matrix))
# Remove self-correlations
cor_df <- cor_df[cor_df$Var1 != cor_df$Var2, ]
# Remove duplicate pairs (symmetry in correlation matrix)
cor_df <- cor_df[!duplicated(t(apply(cor_df[, 1:2], 1, sort))), ]
# Filter for highly correlated pairs
high_cor_df <- cor_df[abs(cor_df$Freq) > threshold, ]
# Keep only one variable from each correlated pair
genes_to_remove <- unique(high_cor_df$Var2)
# Remove redundant features
df_reduced <- train_data[, !(colnames(train_data) %in% genes_to_remove)]
return(df_reduced)
}
results <- data.frame(Iteration = integer(),
NumGenes = integer(),
FeatureSelection = logical(),
Precision = double(),
Sensitivity = double(),
Specificity = double(),
Genes = character(),
stringsAsFactors = FALSE)
set.seed(125)
# LDA Dimensionality Reduction and Model  -- VERSION 1
# The approach using LDA for dimensionality reduction is:
# 1. Identify contribution performance using LDA to get features weights
# 2. Standardized Data
# 3. Random Search for Best Gene Subset
# 4. Prepare training and test sets with selected genes
# 5. Extract metrics
# Load Data
df <- load_gene_subset(group_number = 7, include_class = TRUE)
# Separate predictors and class
genes_only <- df[, setdiff(names(df), "Class")]
labels <- df$Class
all_genes <- colnames(genes_only)
train_index <- createDataPartition(labels, p = 0.8, list = FALSE)
train_genes <- genes_only[train_index, ]
test_genes <- genes_only[-train_index, ]
train_labels <- labels[train_index]
test_labels <- labels[-train_index]
train_df <- data.frame(train_genes, Class = train_labels)
test_df <- data.frame(test_genes, Class = test_labels)
# Save to CSV files
write.csv(train_df, "data/train_data.csv", row.names = FALSE)
write.csv(test_df, "data/test_data.csv", row.names = FALSE)
data <- read_gene_data()
train_genes <- data$train_genes
train_labels <- data$train_labels
test_genes <- data$test_genes
test_labels <- data$test_labels
train_genes <- scale(train_genes)
n_iter <- 30  # number of random samples
gene_range <- 10:60  # range of gene subset sizes to try
results <- data.frame()
for (i in 1:n_iter) {
num_genes <- sample(gene_range, 1)
selected_genes <- sample(all_genes, num_genes)
# Prepare training and test sets with selected genes
train_df <- data.frame(train_genes[, selected_genes], Class = train_labels)
test_df <- data.frame(test_genes, Class = test_labels)
# Compute correlation matrix
train_df <- remove_correlated_features(train_df)
# Fit LDA model
lda_model <- tryCatch({
lda(Class ~ ., data = train_df)
}, error = function(e) return(NULL))
if (!is.null(lda_model)) {
# Predict on test set
test_pred <- predict(lda_model, newdata = test_df)
cm_test <- confusionMatrix(as.factor(test_pred$class), as.factor(test_df$Class), positive = "1")
# Predict on training set
train_pred <- predict(lda_model, newdata = train_df)
cm_train <- confusionMatrix(as.factor(train_pred$class), as.factor(train_df$Class), positive = "1")
# Extract metrics
precision_test <- cm_test$byClass["Pos Pred Value"]
sensitivity_test <- cm_test$byClass["Sensitivity"]
specificity_test <- cm_test$byClass["Specificity"]
precision_train <- cm_train$byClass["Pos Pred Value"]
sensitivity_train <- cm_train$byClass["Sensitivity"]
specificity_train <- cm_train$byClass["Specificity"]
# Append to results
results <- rbind(results, data.frame(
Iteration = i,
NumGenes = num_genes,
FeatureSelection = TRUE,
Precision_Train = precision_train,
Sensitivity_Train = sensitivity_train,
Specificity_Train = specificity_train,
Precision_Test = precision_test,
Sensitivity_Test = sensitivity_test,
Specificity_Test = specificity_test,
Genes = paste(selected_genes, collapse = ",")
)
)
}
}
best_results <- results %>%
filter(
Precision_Train != 1,
Sensitivity_Train != 1,
Specificity_Train != 1,
Precision_Test != 1,
Sensitivity_Test != 1,
Specificity_Test != 1
) %>%
arrange(desc(Precision_Test)) %>%
mutate(
max_precision = max(Precision_Test, na.rm = TRUE),
max_sensitivity = max(Sensitivity_Test, na.rm = TRUE)
) %>%
filter(
Precision_Test == max_precision |
Sensitivity_Test == max_sensitivity
) %>%
select(-max_precision, -max_sensitivity)
best_results <- results %>%
filter(
Precision_Train != 1,
Sensitivity_Train != 1,
Specificity_Train != 1,
Precision_Test != 1,
Sensitivity_Test != 1,
Specificity_Test != 1
) %>%
arrange(desc(Precision_Test)) %>%
mutate(
max_precision = max(Precision_Test, na.rm = TRUE),
max_sensitivity = max(Sensitivity_Test, na.rm = TRUE)
) %>%
filter(
Precision_Test == max_precision |
Sensitivity_Test == max_sensitivity
) %>%
dplyr::select(-max_precision, -max_sensitivity)
View(best_results)
set.seed(125)
# Load Data
df <- load_gene_subset(group_number = 7, include_class = TRUE)
# shuffle data to minimize random effects
shuffled_df <-  df[sample(nrow(df)),]
# Separate predictors and class
genes_only <- shuffled_df[, setdiff(names(shuffled_df), "Class")]
all_genes <- colnames(genes_only)
# Create training 80% and test 20%,
train <- createDataPartition(shuffled_df$Class, p = 0.8, list = FALSE, times = 1)
df_train <- shuffled_df[train,]
df_test <- shuffled_df[-train,]
# 1. Random Forest model using repeated 10-fold cross-validation
# With regression problems the default value is often  mtry = p3 and for classification mtry=âˆšp
num_features <- ncol(df_train) - 1
sqrt_mtry <- floor(sqrt(num_features))
tunegrid_rf <- expand.grid(
mtry = c(max(1, sqrt_mtry - 2), sqrt_mtry, sqrt_mtry + 2)
)
ctrl <- trainControl(
method = "cv",
search = "grid",
number = 10,
classProbs = TRUE,
savePredictions = "final",
summaryFunction = twoClassSummary
)
# Target variable is a factor
df_train$Class <- as.factor(df_train$Class)
levels(df_train$Class) <- make.names(levels(df_train$Class))
model_rf <- train(
Class ~ .,
data = df_train,
method = "rf",
trControl = ctrl,
tuneGrid = expand.grid(mtry = floor(sqrt(ncol(df_train) - 1))),
ntree = 100,
metric = "ROC"
)
roc_obj <- pROC::roc(
response = model_rf$pred$obs,
predictor = model_rf$pred$X1,  # X1 is the class label "1" after make.names()
levels = rev(levels(model_rf$pred$obs))
)
auc_value_rf <- auc(roc_obj)
# Get predicted classes and true labels
predictions <- model_rf$pred$pred
true_labels <- model_rf$pred$obs
# Confusion Matrix
cm <- confusionMatrix(predictions, true_labels)
# Metrics
accuracy_rf <- cm$overall["Accuracy"]
sensitivity_rf <- cm$byClass["Sensitivity"]
specificity_rf <- cm$byClass["Specificity"]
ppv_rf <- cm$byClass["Pos Pred Value"]
npv_rf <- cm$byClass["Neg Pred Value"]
nfeats_rf <- ncol(df_train) - 1
nfeats_norm <- nfeats / max(nfeats, 50)  # 50 is an arbitrary scale max
nfeats_norm <- nfeats_rf / max(nfeats_rf, 50)  # 50 is an arbitrary scale max
metrics_rf <- data.frame(
Model = "RF",
Accuracy = as.numeric(accuracy_rf),
Sensitivity = as.numeric(sensitivity_rf),
Specificity = as.numeric(specificity_rf),
PPV = as.numeric(ppv_rf),
NPV = as.numeric(npv_rf),
AUC = as.numeric(auc_value_rf),
Nfeats = as.numeric(nfeats_rf)
)
metrics_all <- rbind(metrics_rf, metrics_lda)
# === Plotting LDA
# Choose the best row (you can change this logic if needed)
best_lda_row <- best_results[1, ]
# Prepare data for prediction again
selected_genes <- unlist(strsplit(as.character(best_lda_row$Genes), ","))
# Ensure selected genes exist in test set
lda_test_df <- data.frame(test_genes[, selected_genes], Class = test_labels)
lda_train_df <- data.frame(train_genes[, selected_genes], Class = train_labels)
# Refit LDA model
lda_model <- lda(Class ~ ., data = lda_train_df)
lda_pred <- predict(lda_model, newdata = lda_test_df)
# Confusion matrix
cm_lda <- confusionMatrix(
data = as.factor(lda_pred$class),
reference = as.factor(lda_test_df$Class),
positive = "1"
)
# Extract metrics
accuracy_lda <- cm_lda$overall["Accuracy"]
sensitivity_lda <- cm_lda$byClass["Sensitivity"]
specificity_lda <- cm_lda$byClass["Specificity"]
ppv_lda <- cm_lda$byClass["Pos Pred Value"]
npv_lda <- cm_lda$byClass["Neg Pred Value"]
# AUC
roc_lda <- pROC::roc(response = as.factor(lda_test_df$Class),
predictor = lda_pred$posterior[, "1"],
levels = rev(levels(as.factor(lda_test_df$Class))))
auc_lda <- auc(roc_lda)
# Number of features
nfeats_lda <- length(selected_genes)
# Consolidate results in metrics_lda table
metrics_lda <- data.frame(
Model = "LDA",
Accuracy = as.numeric(accuracy_lda),
Sensitivity = as.numeric(sensitivity_lda),
Specificity = as.numeric(specificity_lda),
PPV = as.numeric(ppv_lda),
NPV = as.numeric(npv_lda),
AUC = as.numeric(auc_lda),
Nfeats = as.numeric(nfeats_lda)
)
metrics_all <- rbind(metrics_rf, metrics_lda)
View(metrics_all)
normalize_df <- df %>%
select(-Model) %>%
mutate(across(everything(), ~ rescale(.x, to = c(0, 1))))
normalize_df <- metrics_all_scaled %>%
select(-Model) %>%
mutate(across(everything(), ~ rescale(.x, to = c(0, 1))))
normalize_df <- metrics_all_scaled %>%
select(-Model) %>%
mutate(across(everything(), ~ rescale(.x, to = c(0, 1))))
normalize_df <- metrics_all_scaled %>%
dplyr::select(-Model) %>%
mutate(across(everything(), ~ rescale(.x, to = c(0, 1))))
metrics_all_scaled <- normalize_df(metrics_all)
normalize_df <- metrics_all_scaled %>%
dplyr::select(-Model) %>%
mutate(across(everything(), ~ rescale(.x, to = c(0, 1))))
metrics_all <- rbind(metrics_rf, metrics_lda)
normalize_df <- metrics_all %>%
dplyr::select(-Model) %>%
mutate(across(everything(), ~ rescale(.x, to = c(0, 1))))
radar_data <- rbind(
rep(1, ncol(normalize_df)),  # max values
rep(0, ncol(normalize_df)),  # min values
normalize_df
)
normalize_df <- metrics_all %>%
dplyr::select(-Model) %>%
mutate(across(everything(), ~ rescale(.x, to = c(0, 1))))
normalize_df <- metrics_all %>%
dplyr::select(-Model) %>%
mutate(across(everything(), ~ rescale(.x, to = c(0, 1))))
library(fmsb)      # For radar chart
library(dplyr)     # For data manipulation
library(scales)
metrics_all <- rbind(metrics_rf, metrics_lda)
#Normalize all numeric columns to [0, 1] scale for fair plotting
normalize_df <- metrics_all %>%
dplyr::select(-Model) %>%
mutate(across(everything(), ~ rescale(.x, to = c(0, 1))))
View(normalize_df)
metrics_all <- rbind(metrics_rf, metrics_lda)
normalize_column <- function(x) {
rng <- range(x, na.rm = TRUE)
if (diff(rng) == 0) {
return(rep(0.5, length(x)))  # Constant value case
} else {
return((x - min(x)) / (max(x) - min(x)))
}
}
normalize_df <- df %>%
dplyr::select(-Model) %>%
dplyr::mutate(across(everything(), ~ normalize_column(.x)))
normalize_df <- metrics_all %>%
dplyr::select(-Model) %>%
dplyr::mutate(across(everything(), ~ normalize_column(.x)))
selected_genes <- unlist(strsplit(best_results$Genes[1], split = ","))
df <- load_gene_subset(group_number = 7, include_class = TRUE)
selected_genes <- unlist(strsplit(best_results$Genes[1], split = ","))
selected_genes <- trimws(selected_genes)
df_filtered <- df[, selected_genes, drop = FALSE]
View(df_filtered)
genes_only <- df_filtered[, setdiff(names(df_filtered), "Class")]
labels <- df_filtered$Class
all_genes <- colnames(genes_only)
train_index <- createDataPartition(labels, p = 0.8, list = FALSE)
genes_only <- df_filtered[, setdiff(names(df_filtered), "Class")]
View(genes_only)
labels <- df_filtered$Class
df <- load_gene_subset(group_number = 7, include_class = TRUE)
selected_genes <- unlist(strsplit(best_results$Genes[1], split = ","))
selected_genes <- trimws(selected_genes)
#Make sure to filter contributing genes and class label in the df_filtered
df_filtered <- df[, selected_genes, drop = FALSE]
df_filtered <- df[, c(selected_genes, "Class")]
genes_only <- df_filtered[, setdiff(names(df_filtered), "Class")]
labels <- df_filtered$Class
all_genes <- colnames(genes_only)
train_index <- createDataPartition(labels, p = 0.8, list = FALSE)
set.seed(125)
# Load Data filter using feature selection from first point
df <- load_gene_subset(group_number = 7, include_class = TRUE)
selected_genes <- unlist(strsplit(best_results$Genes[1], split = ","))
selected_genes <- trimws(selected_genes)
#Make sure to filter contributing genes and class label in the df_filtered
df_filtered <- df[, selected_genes, drop = FALSE]
df_filtered <- df[, c(selected_genes, "Class")]
# Separate predictors and class
genes_only <- df_filtered[, setdiff(names(df_filtered), "Class")]
labels <- df_filtered$Class
all_genes <- colnames(genes_only)
# Create stratified train/test split
train_index <- createDataPartition(labels, p = 0.8, list = FALSE)
train_genes <- genes_only[train_index, ]
test_genes <- genes_only[-train_index, ]
train_labels <- labels[train_index]
test_labels <- labels[-train_index]
set.seed(125)
# Load Data filter using feature selection from first point
df <- load_gene_subset(group_number = 7, include_class = TRUE)
selected_genes <- unlist(strsplit(best_results$Genes[1], split = ","))
selected_genes <- trimws(selected_genes)
#Make sure to filter contributing genes and class label in the df_filtered
df_filtered <- df[, selected_genes, drop = FALSE]
df_filtered <- df[, c(selected_genes, "Class")]
# Separate predictors and class
genes_only <- df_filtered[, setdiff(names(df_filtered), "Class")]
labels <- df_filtered$Class
all_genes <- colnames(genes_only)
# Create stratified train/test split
train_index <- createDataPartition(labels, p = 0.8, list = FALSE)
train_genes <- genes_only[train_index, ]
test_genes <- genes_only[-train_index, ]
train_labels <- labels[train_index]
test_labels <- labels[-train_index]
# Standardize training data
train_genes <- scale(train_genes)
#Combine dataframes
train_df <- data.frame(train_genes, Class = train_labels)
test_df <- data.frame(test_genes, Class = test_labels)
ctrl_svm <- trainControl(
method = "cv",
search = "grid",
number = 10,
classProbs = TRUE,
savePredictions = "final",
summaryFunction = twoClassSummary
)
# Train SVM model with cross-validation and considering feature selection from LDA
model_sv <- train(
Class ~ .,
data = train_df,
method = "svmRadial",
trControl = ctrl_svm,
ntree = 100,
tuneLength = 10
)
ctrl_svm <- trainControl(
method = "cv",
search = "grid",
number = 10,
classProbs = TRUE,
savePredictions = "final",
summaryFunction = twoClassSummary
)
# Train SVM model with cross-validation and considering feature selection from LDA
model_sv <- train(
Class ~ .,
data = train_df,
method = "svmRadial",
trControl = ctrl_svm,
ntree = 100,
tuneLength = 10
)
install.packages("/PATH/TO/YOUR/kernlab.tar.gz", repos = NULL)
install.packages("kernlab", type="source")
install.packages("kernlab", version = "0.9-33")
install.packages("kernlab", version = "0.9-25")
ctrl_svm <- trainControl(
method = "cv",
search = "grid",
number = 10,
classProbs = TRUE,
savePredictions = "final",
summaryFunction = twoClassSummary
)
# Train SVM model with cross-validation and considering feature selection from LDA
model_sv <- train(
Class ~ .,
data = train_df,
method = "svmRadial",
trControl = ctrl_svm,
ntree = 100,
tuneLength = 10
)
install.packages("kernlab", version = "0.9-20")
