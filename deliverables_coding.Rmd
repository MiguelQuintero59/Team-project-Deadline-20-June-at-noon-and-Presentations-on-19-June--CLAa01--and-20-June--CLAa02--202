---
title: "Group Project"
output: pdf_document
date: "2025-06-03"
---

# FUNCTIONS
```{r setup, include=FALSE}

load_gene_subset <- function(group_number,
                             expression_file = "gene-expression-invasive-vs-noninvasive-cancer.csv",
                             subset_file = "teamsubsets.csv",
                             include_class = TRUE) {
  library(dplyr)
  library(caret)
  library(glmnet)
  library(ggplot2)
  library(reshape2)
  library(pheatmap)
  library(MASS)

  # Load main dataset
  dataframe <- read.csv(file = expression_file)

  # Load subset file
  df_subsets <- read.csv(file = subset_file, sep = ' ')

  # Filter by group number
  reg_id <- df_subsets[group_number, ]

  # Extract gene indices (remove the ID column)
  subsets <- as.numeric(reg_id[-1])

  # Filter gene expression dataframe using selected gene indices
  df <- dataframe[, subsets]

  # Optionally, add class and cancer type
  if (include_class) {
    df$Class <- dataframe$Class
  }

  return(df)
}

# Initialize empty results data frame
results_table <- data.frame(
  Model = character(),
  Hyperparameter = character(),
  Precision = numeric(),
  Sensitivity = numeric(),
  Specificity = numeric(),
  stringsAsFactors = FALSE
)

# Define the function
add_results <- function(model, hyperparameter, precision, sensitivity, specificity) {
  new_row <- data.frame(
    Model = model,
    Hyperparameter = hyperparameter,
    Precision = precision,
    Sensitivity = sensitivity,
    Specificity = specificity,
    stringsAsFactors = FALSE
  )
  
  # Use global assignment to update results_table
  assign("results_table", rbind(results_table, new_row), envir = .GlobalEnv)
}

# Fisher Criterion Function (for multiple features)
fisher_criterion <- function(X, y) {
  classes <- unique(y)
  if (length(classes) != 2) stop("Only works for binary classification.")
  
  X1 <- X[y == classes[1], , drop = FALSE]
  X2 <- X[y == classes[2], , drop = FALSE]
  
  mean1 <- colMeans(X1)
  mean2 <- colMeans(X2)
  
  Sw1 <- cov(X1)
  Sw2 <- cov(X2)
  Sw <- Sw1 + Sw2
  
  n1 <- nrow(X1)
  n2 <- nrow(X2)
  mean_diff <- matrix(mean1 - mean2, ncol = 1)
  Sb <- (n1 * n2) / (n1 + n2) * (mean_diff %*% t(mean_diff))
  
  J <- sum(diag(Sb)) / sum(diag(Sw))
  return(J)
}

read_gene_data <- function(train_path = "train_data.csv", test_path = "test_data.csv") {
  # Read the CSV files
  train_df <- read.csv(train_path)
  test_df <- read.csv(test_path)
  
  # Split into genes and labels
  train_genes <- train_df[, !(names(train_df) %in% "Class")]
  train_labels <- train_df$Class
  
  test_genes <- test_df[, !(names(test_df) %in% "Class")]
  test_labels <- test_df$Class
  
  # Return as a list
  return(list(
    train_genes = train_genes,
    train_labels = train_labels,
    test_genes = test_genes,
    test_labels = test_labels
  ))
}


```

# FEATURE SELECTION
# To tackle the first point we implmented different techniques to approach different point of views

# The goal of feature selection is to highligth those features that have contribution performance towards the prediction variable. 
# LDA (weights) - FEATURE SELECTION 
```{r setup, include=FALSE}
# LDA Dimensionality Reduction and Model  -- VERSION 1
# The approach using LDA for dimensionality reduction was: 
# 1. Identify contribution performance using LDA to get features weights
# 2. Perform correlation matrix
# 3. Compute LDA weights


set.seed(123) 
results <- data.frame(Iteration = integer(),
                      NumGenes = integer(),
                      Precision = double(),
                      Sensitivity = double(),
                      Specificity = double(),
                      Genes = character(),
                      stringsAsFactors = FALSE)

# Load Data
df <- load_gene_subset(group_number = 7, include_class = TRUE)

# Extract Predictors
gene_data <- df[, setdiff(names(df), "Class")]

#To avoid collinearity (redundant variables) removed correlated features
# Compute correlation matrix
cor_matrix <- cor(df, method = "pearson", use = "pairwise.complete.obs")
cor_df <- as.data.frame(as.table(cor_matrix))

# Remove self-correlations
cor_df <- cor_df[cor_df$Var1 != cor_df$Var2, ]

#Remove duplicate pairs (since correlation matrix is symmetric)
cor_df <- cor_df[!duplicated(t(apply(cor_df[, 1:2], 1, sort))), ]

# Filter for highly correlated pairs (e.g., |r| > 0.9)
high_cor_df <- cor_df[abs(cor_df$Freq) > 0.8, ]

# Strategy: Keep only one variable from each correlated pair
genes_to_remove <- unique(high_cor_df$Var2)
length(genes_to_remove)

# Create reduced dataframe by removing redundant genes
df_reduced <- df[, !(colnames(df) %in% genes_to_remove)]

# Separate predictors and class
genes_only <- df_reduced[, setdiff(names(df_reduced), "Class")]
labels <- df_reduced$Class
all_genes <- colnames(genes_only)

# Create stratified train/test split
train_index <- createDataPartition(labels, p = 0.8, list = FALSE)
train_genes <- genes_only[train_index, ]
test_genes <- genes_only[-train_index, ]
train_labels <- labels[train_index]
test_labels <- labels[-train_index]

# Column-wise means
train_means <- colMeans(train_genes)
test_means <- colMeans(test_genes)

# Column-wise variances
train_vars <- apply(train_genes, 2, var)
test_vars  <- apply(test_genes, 2, var)

# Global average mean and variance to avoid Data Leakage
overall_train_mean <- mean(train_means)
overall_test_mean <- mean(test_means)

overall_train_var <- mean(train_vars)
overall_test_var <- mean(test_vars)

cat("Train Mean:", overall_train_mean, "\n")
cat("Test Mean:", overall_test_mean, "\n")
cat("Train Variance:", overall_train_var, "\n")
cat("Test Variance:", overall_test_var, "\n")


# ---------- Save Training and Test Data ----------
# Combine gene expression and class label
#train_df <- data.frame(train_genes, Class = train_labels)
#test_df <- data.frame(test_genes, Class = test_labels)

# Save to CSV files
#write.csv(train_df, "train_data.csv", row.names = FALSE)
#write.csv(test_df, "test_data.csv", row.names = FALSE)
# -----------------------------------------------

# === Random Search for Best Gene Subset ===
n_iter <- 30  # number of random samples
gene_range <- 10:60  # range of gene subset sizes to try
results <- data.frame()


for (i in 1:n_iter) {
  num_genes <- sample(gene_range, 1)
  selected_genes <- sample(all_genes, num_genes)
  
  # Prepare data
  df_filtered <- data.frame(genes_only[, selected_genes], Class = labels)
  
  # Prepare training and test sets with selected genes
  train_df <- data.frame(train_genes[, selected_genes], Class = train_labels)
  test_df <- data.frame(test_genes[, selected_genes], Class = test_labels)
  
  
  # Fit LDA model
  lda_model <- tryCatch({
    lda(Class ~ ., data = train_df)
  }, error = function(e) return(NULL))
  
  if (!is.null(lda_model)) {
    # Predict on test set
    test_pred <- predict(lda_model, newdata = test_df)
    cm_test <- confusionMatrix(as.factor(test_pred$class), as.factor(test_df$Class), positive = "1")
    
    # Predict on training set
    train_pred <- predict(lda_model, newdata = train_df)
    cm_train <- confusionMatrix(as.factor(train_pred$class), as.factor(train_df$Class), positive = "1")
    
    # Extract metrics
    precision_test <- cm_test$byClass["Pos Pred Value"]
    sensitivity_test <- cm_test$byClass["Sensitivity"]
    specificity_test <- cm_test$byClass["Specificity"]
    
    precision_train <- cm_train$byClass["Pos Pred Value"]
    sensitivity_train <- cm_train$byClass["Sensitivity"]
    specificity_train <- cm_train$byClass["Specificity"]
    
    # Append to results
    results <- rbind(results, data.frame(
      Iteration = i,
      NumGenes = num_genes,
      
      Precision_Train = precision_train,
      Sensitivity_Train = sensitivity_train,
      Specificity_Train = specificity_train,
      
      Precision_Test = precision_test,
      Sensitivity_Test = sensitivity_test,
      Specificity_Test = specificity_test,
      
      Genes = paste(selected_genes, collapse = ",")
    ))
  }
}

# Sort by precision or another metric of your choice
top_results <- results[order(-results$Precision_Train), ]

top_results <- top_results[
  top_results$NumGenes >= 35 &
  top_results$Precision_Train != 1 &
  top_results$Sensitivity_Train != 1 &
  top_results$Specificity_Train != 1,
]

# Show top-performing gene sets
print(head(top_results, 5))



```
